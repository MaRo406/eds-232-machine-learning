{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Discussion 6\n",
        "subtitle: Random Forests with Imputed Data\n",
        "description: 'Thursday, February 13th, 2025'\n",
        "jupyter:\n",
        "  jupytext:\n",
        "    text_representation:\n",
        "      extension: .qmd\n",
        "      format_name: quarto\n",
        "      format_version: '1.0'\n",
        "      jupytext_version: 1.16.4\n",
        "  kernelspec:\n",
        "    display_name: EDS 232 Environment\n",
        "    language: python\n",
        "    name: eds232_env\n",
        "---\n",
        "\n",
        "\n",
        "### Introduction\n",
        "\n",
        "In this week's discussion section, we will use a data with few NAs and intentionally add more NAs to it. We are going to run different imputation strategies on our newly \"NA-ed\" dataset, and see which performs best. Normally, you would never know how your imputation is actually performing, but this excercise will allow us to look under the hood  a bit at how different imputation strategies perform differently. Once we find which imputation strategy works best, we will run a random forest on both the original data, as well as our newly imputed data. Which do you think will perform better?? \n",
        "\n",
        "## Data \n",
        "\n",
        "This week, we will be working with mushroom data! This dataset from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/73/mushroom) includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family. Our target variable will be, `poisonous`, a categorical outcome variable classifying the mushroom as poisonous or not. We will include 22 features in our dataset that all relate to mushroom characteristics- such as `cap-cut`, `cap-surface`, `bruises`, and `odor`. \n",
        "\n",
        "## Excercise\n",
        "\n",
        "#### Import Libraries\n"
      ],
      "id": "d74cbca7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, r2_score\n",
        "from ucimlrepo import fetch_ucirepo "
      ],
      "id": "bae8cceb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load Data\n"
      ],
      "id": "ef0fdab0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fetch dataset \n",
        "mushroom = fetch_ucirepo(id=73) \n",
        "  \n",
        "# Save data as X and y variables\n",
        "X = mushroom.data.features \n",
        "y = np.ravel(mushroom.data.targets)\n",
        "\n",
        "# Expand dataframe columns and look at view dataframe\n",
        "pd.set_option('display.max_columns', None)\n",
        "X.head()"
      ],
      "id": "4c666713",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Encoding Data\n"
      ],
      "id": "460d91ba"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Factorize all columns\n",
        "for col in X.columns: \n",
        "    X.loc[:, col] = pd.factorize(X[col], sort = True)[0]\n",
        "\n",
        "# View first few rows of encoded data\n",
        "X.iloc[0:5, 0:5]"
      ],
      "id": "98d5bde9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Time to impute! \n",
        "\n",
        "Does our dataset have any missing values? Lets check! \n"
      ],
      "id": "2574fc06"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check for NAs\n",
        "X.isna().sum()"
      ],
      "id": "4841344c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are going to randomly assign observations in our dataset to be missing, and then see which imputation methods perform best by comparing their results to our actual dataset. Let's randomly assign NA observations throughout our dataset. We will create a copy of our dataframe and call it `X_Na`.\n"
      ],
      "id": "89211a8e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create copy of X variables\n",
        "X_Na = X.copy()"
      ],
      "id": "e8de6022",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Assign 10% of new dataframe with NA values\n",
        "for col in X_Na.columns: \n",
        "    X_Na.loc[X_Na.sample(frac = 0.1).index, col] = np.nan"
      ],
      "id": "a97bc06a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check to make sure there are missing values\n",
        "X_Na.isna().sum()"
      ],
      "id": "fead21ca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have our dataset with missing values, let's impute! \n",
        "\n",
        "##### Imputation method #1: Filling NA values with the mode\n"
      ],
      "id": "6596ce79"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Impute with mode\n",
        "X_mode_impute = X_Na.fillna(X_Na.mode().iloc[0])\n",
        "\n",
        "# Check to make sure there are no NAs\n",
        "X_mode_impute.isna().sum()"
      ],
      "id": "46250814",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Imputation method #2: Filling NA values with the median using `SimpleImputer`\n"
      ],
      "id": "6b5ae9d3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Impute with median (using SimpleImputer) \n",
        "median_impute = SimpleImputer(strategy = 'median')\n",
        "X_median_impute = median_impute.fit_transform(X_Na)\n",
        "X_median_impute = pd.DataFrame(X_median_impute, columns = X.columns)\n",
        "\n",
        "# Check to make sure there are no NAs\n",
        "X_median_impute.isna().sum()"
      ],
      "id": "4210e56c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Imputation method #3: Filling NA values with KNN Imputer\n"
      ],
      "id": "04e685e1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Impute with KNN Imputer\n",
        "knn_impute = KNNImputer(n_neighbors = 20)\n",
        "X_knn_impute = knn_impute.fit_transform(X_Na)\n",
        "X_knn_impute = pd.DataFrame(X_knn_impute, columns = X_Na.columns)\n",
        "\n",
        "# Check to make sure there are no NAs\n",
        "X_knn_impute.isna().sum()"
      ],
      "id": "55111d33",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Now that we have four different dataframes with four different imputation methods, lets see which best captured our real data!We can do this using the mean squared error!  \n"
      ],
      "id": "73e2bad7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate imputation accuracy using mean squared error\n",
        "mse_mode = mean_squared_error(X, X_mode_impute)\n",
        "mse_median = mean_squared_error(X, X_median_impute)\n",
        "mse_knn = mean_squared_error(X, X_knn_impute)\n",
        "\n",
        "\n",
        "# Report results\n",
        "print(f\"Mode imputation performance: {mse_mode}\")\n",
        "print(f\"Median Imputation performance: {mse_median}\")\n",
        "print(f\"KNN Imputation performance: {mse_knn}\")"
      ],
      "id": "f8698616",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate imputation accuracy using R2\n",
        "r2_mode = r2_score(X, X_mode_impute)\n",
        "r2_median = r2_score(X, X_median_impute)\n",
        "r2_knn = r2_score(X, X_knn_impute)\n",
        "\n",
        "\n",
        "# Report results\n",
        "print(f\"Mode imputation performance: {r2_mode}\")\n",
        "print(f\"Median Imputation performance: {r2_median}\")\n",
        "print(f\"KNN Imputation performance: {r2_knn}\")"
      ],
      "id": "831d5a7e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It looks like our KNN Imputation was the most successfull in imputing NAs! Let's run a random forest with our actual data, and our KNN imputed data to see how/if they differ! \n",
        "\n",
        "### Random Forest Classifier with original data\n"
      ],
      "id": "6648d411"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Split actual data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
      ],
      "id": "b6df2b77",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Number of features to include for tuning\n",
        "num_features = [1,4,7,10,13,16,19,22]\n",
        "accuracy = []\n",
        "\n",
        "for feature in num_features: \n",
        "    rf_classifier = RandomForestClassifier(\n",
        "        n_estimators = 50, \n",
        "        max_depth = 3, \n",
        "        random_state = 42, \n",
        "        max_features = feature\n",
        "    )\n",
        "    \n",
        "    # Train model\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "    \n",
        "    # Predict and evaluate \n",
        "    y_pred = rf_classifier.predict(X_test)\n",
        "    rf_accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracy.append(rf_accuracy)\n",
        "    print(f\"Number of features: {feature}; Random Forest Accuracy: {rf_accuracy}\")"
      ],
      "id": "4625c10e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Random Forest Classifier with imputed data:\n"
      ],
      "id": "afbc4623"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Split imputed data \n",
        "X_train, X_test, y_train, y_test = train_test_split(X_knn_impute, y, test_size = 0.3, random_state = 42)"
      ],
      "id": "96adff47",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Number of features to include for tuning\n",
        "# Number of features to include for tuning\n",
        "num_features = [1,4,7,10,13,16,19,22]\n",
        "accuracy = []\n",
        "\n",
        "for feature in num_features: \n",
        "    rf_classifier = RandomForestClassifier(\n",
        "        n_estimators = 50, \n",
        "        max_depth = 3, \n",
        "        random_state = 42, \n",
        "        max_features = feature\n",
        "    )\n",
        "    \n",
        "    # Train model\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "    \n",
        "    # Predict and evaluate \n",
        "    y_pred = rf_classifier.predict(X_test)\n",
        "    rf_accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracy.append(rf_accuracy)\n",
        "    print(f\"Number of features: {feature}; Random Forest Accuracy: {rf_accuracy}\")"
      ],
      "id": "36ab78e9",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "EDS 232 Environment",
      "language": "python",
      "name": "eds232_env"
    },
    "kernel": "eds232_env",
    "jupytext": {
      "text_representation": {
        "extension": ".qmd",
        "format_name": "quarto",
        "format_version": "1.0",
        "jupytext_version": "1.16.4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}