{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Discussion 7\n",
        "subtitle: NLP with Logistic Regression\n",
        "description: 'Thursday, February 20th, 2025'\n",
        "jupyter:\n",
        "  jupytext:\n",
        "    text_representation:\n",
        "      extension: .qmd\n",
        "      format_name: quarto\n",
        "      format_version: '1.0'\n",
        "      jupytext_version: 1.16.4\n",
        "  kernelspec:\n",
        "    display_name: EDS 232\n",
        "    language: python\n",
        "    name: eds232_env\n",
        "---\n",
        "\n",
        "\n",
        "### Introduction\n",
        "\n",
        "In this week's discussion section, we will use a dataset containing tweets related to different disasters. For each observation (tweet), there is an outcome variable that classifies the disasters talked about in the tweet as real (1), or not (0). Rather than having multiple predictors as our `X`, we will have one predictor - the tweet. However, each individual word can be thought of as their own predictor, each contributing to predicting our outcome variable. \n",
        "\n",
        "### Data \n",
        "\n",
        "The dataset this week is a commonly used dataset for NLP (Natural Language Processing).  The dataset can be found [here](https://docs.google.com/spreadsheets/d/1SILdL2TBuglkZDQgzi7M0RTC4n-WHWOaCqd9hAVKa7c/edit?usp=sharing). `Disasters.csv` includes a `text` variable, which contains the tweet as a string. Our target variable, `target`, is a binary outcome variable with 1 representing the disaster discussed as real, and 0 representing the disaster discussed as not real.  \n",
        "\n",
        "### Excercise\n",
        "\n",
        "#### Load in libraries and data\n"
      ],
      "id": "140f4e16"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "import re\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "id": "7bcf910d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read in the data\n",
        "disaster = pd.read_csv('../data/disaster.csv')"
      ],
      "id": "7c270125",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Clean text data\n",
        "Work with a partner and annotate what each line in the code chunk below is doing. \n"
      ],
      "id": "7d1f95aa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cleaning of text data\n",
        "def preprocess(text):\n",
        "    text = text.lower() # Converts to lowercase\n",
        "    text=text.strip()  # Removes leading/ trailing whitespace\n",
        "    text=re.sub(r'<.*?>','', text) # Remove html sytax \n",
        "    text = re.sub(r'[^\\w\\s]','',text)  # removes punctuation\n",
        "    text = re.sub(r'\\[[0-9]*\\]',' ',text)  # removes references\n",
        "    text = re.sub(r'\\d',' ',text) # removes digits\n",
        "    text = re.sub(r'\\s+', ' ', text) # collapse multiple spaces into a single space\n",
        "    return text"
      ],
      "id": "9d7dc33d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Apply string cleaning to text variable\n",
        "disaster['clean_text'] = disaster['text'].apply(preprocess)\n",
        "disaster.head()"
      ],
      "id": "61b7e564",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### What about stop words?\n"
      ],
      "id": "0abb175e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Proof that Tfidf veoctorizer excludes stopwords\n",
        "stop_words_ex = [\"On March 5th, I will crush my capstone presentation with my awesome team!\"]\n",
        "\n",
        "vectorizer_english = TfidfVectorizer(stop_words = \"english\")\n",
        "vectorizer_english.fit_transform(stop_words_ex)\n",
        "\n",
        "print(\"Remaining words\")\n",
        "print(vectorizer_english.get_feature_names_out())"
      ],
      "id": "610f0722",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Logistic Regression\n"
      ],
      "id": "a1f3ee55"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Split into test and train\n",
        "X_train, X_test, y_train, y_test = train_test_split(disaster[\"clean_text\"], disaster['target'], test_size = 0.3, random_state = 42)"
      ],
      "id": "a08c7edb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Vectorize words \n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words = \"english\")\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
      ],
      "id": "ab1d0b7f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Initialize a logistic regression model and fit to vectorized training data\n",
        "lr_model = LogisticRegression(random_state = 42)\n",
        "lr_model.fit(X_train_tfidf, y_train)\n",
        "y_pred = lr_model.predict(X_test_tfidf)"
      ],
      "id": "ae3ed5c4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Logistic Regression Results\n"
      ],
      "id": "a45815ef"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate LR accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Create confusion matrix for correctly/incorrectly predicting outcome variable\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize = (8,6))\n",
        "sns.heatmap(cm, annot = True, fmt = 'd', cmap = \"GnBu\",\n",
        "           xticklabels = [\"No disaster\", \"Disaster\"],\n",
        "           yticklabels = [\"No Disaster\", 'Disaster'])\n",
        "plt.title('Logisitc Regression Model Performance')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicated Label')\n",
        "plt.show()"
      ],
      "id": "c0362e67",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Test model with new data\n"
      ],
      "id": "937f9784"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "new_text = [\n",
        "    \"BREAKING: Massve earthquake hits the coast\",\n",
        "    \"I love watching disaster movies on Netflix\",\n",
        "    \"Thousands evacuated as hurricance approaches\",\n",
        "    \"Theeeesssss is a disassterrrrr\",\n",
        "    \"It's Windy!\",\n",
        "    \"The Palisade fire has damaged over 7,000 structures.\",\n",
        "    \"The Palisade wildfire has damaged over 7,000 structures.\",\n",
        " \n",
        "]\n",
        "\n",
        "# Preprocess new phrases\n",
        "cleaned_new_text =[preprocess(text) for text in new_text]\n",
        "\n",
        "# Transform using TF-IDF vectorizer\n",
        "new_features = tfidf_vectorizer.transform(cleaned_new_text)\n",
        "\n",
        "# Make predictions\n",
        "\n",
        "predictions = lr_model.predict(new_features)\n",
        "\n",
        "# Check outcomes\n",
        "for text, pred in zip(new_text, predictions):\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Prediction: {'Real Disaster' if pred == 1 else 'Not a Real Disaster'}\\n\")"
      ],
      "id": "7d34435f",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "EDS 232",
      "language": "python",
      "name": "eds232_env"
    },
    "kernel": "eds232_env",
    "jupytext": {
      "text_representation": {
        "extension": ".qmd",
        "format_name": "quarto",
        "format_version": "1.0",
        "jupytext_version": "1.16.4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}